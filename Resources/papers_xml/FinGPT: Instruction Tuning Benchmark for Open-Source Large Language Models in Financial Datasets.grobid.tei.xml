<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coords="1,144.27,101.17,323.84,15.48;1,157.04,121.09,297.93,15.48;1,238.34,141.02,135.33,15.48">FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets</title>
				<funder ref="#_Rb3U6em">
					<orgName type="full">National Natural Science Foundation of China</orgName>
					<orgName type="abbreviated">NNSFC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-11-11">11 Nov 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.02,198.50,49.44,8.96"><forename type="first">Neng</forename><surname>Wang</surname></persName>
							<email>nengwang19@ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.72,198.50,51.84,8.96"><forename type="first">Bruce</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.10,198.50,87.92,8.96"><forename type="first">Christina</forename><forename type="middle">Dan</forename><surname>Wang</surname></persName>
							<email>christina.wang@nyu.edu</email>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Shanghai Frontiers Science Center of Artificial Intelligence and Deep Learning</orgName>
								<orgName type="department" key="dep2">Business Division</orgName>
								<orgName type="department" key="dep3">Shanghai Frontiers Science Center of Artificial Intelligence and Deep Learning</orgName>
								<orgName type="department" key="dep4">Business Division</orgName>
								<orgName type="institution" key="instit1">NYU Shanghai</orgName>
								<orgName type="institution" key="instit2">NYU Shanghai</orgName>
								<orgName type="institution" key="instit3">NYU Shanghai</orgName>
								<orgName type="institution" key="instit4">NYU Shanghai</orgName>
								<address>
									<postCode>200122</postCode>
									<country>Shanghai China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coords="1,144.27,101.17,323.84,15.48;1,157.04,121.09,297.93,15.48;1,238.34,141.02,135.33,15.48">FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-11-11">11 Nov 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">0BE8DA656F0966345D3463AD0C7278FE</idno>
					<idno type="arXiv">arXiv:2310.04793v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-11T09:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the swiftly expanding domain of Natural Language Processing (NLP), the potential of GPT-based models for the financial sector is increasingly evident. However, the integration of these models with financial datasets presents challenges, notably in determining their adeptness and relevance. This paper introduces a distinctive approach anchored in the Instruction Tuning paradigm for opensource large language models, specifically adapted for financial contexts. Through this methodology, we capitalize on the interoperability of open-source models, ensuring a seamless and transparent integration. We begin by explaining the Instruction Tuning paradigm, highlighting its effectiveness for immediate integration. The paper presents a benchmarking scheme designed for end-to-end training and testing, employing a cost-effective progression. Firstly, we assess basic competencies and fundamental tasks, such as Named Entity Recognition (NER) and sentiment analysis to enhance specialization. Next, we delve into a comprehensive model, executing multi-task operations by amalgamating all instructional tunings to examine versatility. Finally, we explore the zero-shot capabilities by earmarking unseen tasks and incorporating novel datasets to understand adaptability in uncharted terrains. Such a paradigm fortifies the principles of openness and reproducibility, laying a robust foundation for future investigations in open-source financial large language models (FinLLMs). The codes have been open-sourced at <ref type="url" coords="1,143.87,526.34,243.57,8.30" target="https://github.com/AI4Finance-Foundation/FinGPT">https://github.com/AI4Finance-Foundation/FinGPT</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural Language Processing (NLP) stands as a beacon for the financial sector <ref type="bibr" coords="1,421.07,581.56,15.73,8.64" target="#b32">[35,</ref><ref type="bibr" coords="1,439.28,581.56,12.43,8.64" target="#b24">26,</ref><ref type="bibr" coords="1,454.20,581.56,11.79,8.64" target="#b11">13]</ref>, offering groundbreaking opportunities and potential transformations. Large language models (LLMs) <ref type="bibr" coords="1,477.51,592.47,15.72,8.64" target="#b26">[29,</ref><ref type="bibr" coords="1,495.73,592.47,8.27,8.64" target="#b4">5]</ref> grounded in the GPT framework are emerging as a focal point of interest, promising enhanced financial data interpretation and utilization. Instruction Tuning <ref type="bibr" coords="1,356.94,614.29,15.71,8.64" target="#b28">[31,</ref><ref type="bibr" coords="1,375.14,614.29,13.24,8.64" target="#b18">20]</ref> efficiently adapts pre-trained LLMs to specific tasks, significantly saving time and computational resources without starting training from scratch. This cost-effective approach utilizes open-source models through an Instruction Tuning pipeline, achieving or even surpassing the performance of closed-source counterparts with minimal resource investment. Yet, the challenge remains in adeptly integrating these models, maintaining transparency, and ensuring their seamless adaptability to varied financial tasks.</p><p>Existing methods, while revolutionary in their own rights, fall short in certain key areas. Some models face obstacles in effortless integration with diverse financial datasets <ref type="bibr" coords="2,394.93,113.68,15.89,8.64" target="#b14">[16,</ref><ref type="bibr" coords="2,414.07,113.68,11.92,8.64" target="#b15">17]</ref>. Others, although proficient in general contexts, might falter when exposed to intricate financial terminologies and scenarios <ref type="bibr" coords="2,146.35,135.50,10.68,8.64" target="#b1">[2,</ref><ref type="bibr" coords="2,159.05,135.50,11.74,8.64" target="#b30">33]</ref>. Hence, there's an evident need for a more comprehensive, transparent, and adaptable model catering specifically to the financial domain.</p><p>In this paper, we propose a novel scheme that utilizes the Instruction Tuning paradigm to magnify the capabilities of LLMs within the financial sphere. The proposed scheme stands out due to its emphasis on transparency, reproducibility, and the plug-and-play nature of model integration. Our works encompass the presentation of the Instruction Tuning paradigm, a deep-dive evaluation into the financial understanding of prevalent models, and an in-depth discussion of our methodological approach, which ensures a consistent training regimen. We bridge the gap between open-source models and financial data, ensuring a harmonious confluence.</p><p>Our contributions can be summarized as follows:</p><p>• Instruction tuning paradigm: We present an Instruction Tuning paradigm, specifically tailored for open-source Large Language Models (LLMs) in the financial sector. This approach not only addresses integration challenges but also enhances the adaptability and relevance of transformer-based models for various financial datasets.</p><p>• Cost-effective benchmarking scheme: We introduce a benchmarking process designed with a cost-effective and end-to-end training and testing strategy. This scheme is not only tailored for financial contexts but also ensures a comprehensive and systematic evaluation of LLMs from basic competencies to complex, multi-task operations.</p><p>• Deep insights into various base models: Our work offers a detailed exploration and clarification of various open-source base models such as Llama2, Falcon, ChatGLM2. By highlighting its potential for immediate and transparent integration into the financial sector, we provide valuable insights and plug-and-play guidance for researchers and practitioners working with financial tasks.</p><p>• Promotion of openness and reproducibility: Our methodology adheres to and advocates for the principles of openness and reproducibility in the research and development of opensource FinLLMs. This contribution lays a solid foundation for future research, facilitating further investigation and development in the field.</p><p>The remaining sections of this paper are organized as follows: Section 2 shows the related work; Section 3 delves into the intricacies of the Instruction Tuning paradigm; Section 4 presents our implementation Detail; Section 5 outlines the experiment results; and Section 6 concludes the study with potential future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Recent years have seen a surge in research focused on amalgamating financial datasets with GPTbased models like GPT-3 and GPT-4 <ref type="bibr" coords="2,259.51,574.07,11.75,8.64" target="#b4">[5]</ref> for enhanced NLP applications. Generally, there are two prevailing methodologies: Firstly, employing prompt engineering <ref type="bibr" coords="2,381.55,584.97,15.88,8.64" target="#b37">[40,</ref><ref type="bibr" coords="2,400.68,584.97,12.50,8.64" target="#b29">32,</ref><ref type="bibr" coords="2,416.43,584.97,13.35,8.64" target="#b10">12]</ref> with open-source LLMs, keeping parameters intact; and secondly, using supervised fine-tuning methods such as Instruction Tuning <ref type="bibr" coords="2,184.48,606.79,16.60,8.64" target="#b18">[20]</ref> to craft domain-centric LLMs specially designed for financial tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">General Large Language Models</head><p>• Llama2 <ref type="bibr" coords="2,179.29,649.40,16.65,8.64" target="#b27">[30]</ref> is an open-source LLM developed by Meta, supports 20 languages, building upon its predecessor Llama 1 <ref type="bibr" coords="2,263.12,660.31,15.27,8.64" target="#b26">[29]</ref>.</p><p>• ChatGLM2 <ref type="bibr" coords="2,197.17,676.00,15.89,8.64" target="#b35">[38,</ref><ref type="bibr" coords="2,215.55,676.00,8.36,8.64" target="#b6">7]</ref> emerges as a bilingual model based on the General Language Model (GLM) framework <ref type="bibr" coords="2,220.65,686.91,10.58,8.64" target="#b7">[8]</ref>, supporting English and Chinese.</p><p>• BLOOM <ref type="bibr" coords="2,183.98,702.61,15.16,8.64" target="#b20">[22]</ref>, is the world's largest open multilingual language model, supports 46 natural languages and 13 programming languages, serving as a comprehensive multilingual solution. • MPT <ref type="bibr" coords="3,168.63,372.33,16.64,8.64" target="#b25">[27]</ref> by MosaicML, pre-trained on English text and code, boasts an optimized architecture, making it efficient for both training and inference tasks.</p><p>• Qwen <ref type="bibr" coords="3,171.03,402.64,11.56,8.64" target="#b2">[3]</ref> from Alibaba stands out for its prowess in both Chinese and English, making it a versatile tool for multilingual applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Financial Large Language Models</head><p>• FinBert <ref type="bibr" coords="3,180.61,463.85,11.75,8.64" target="#b1">[2]</ref> is a dedicated model for financial sentiment analysis with under one billion parameters, fine-tuned on a rich financial corpus to excel in finance-specific tasks.</p><p>• FLUE <ref type="bibr" coords="3,174.09,494.16,16.73,8.64" target="#b21">[23]</ref> offers a benchmark derived from five varied financial datasets, acting as an exhaustive evaluation tool for financial language understanding. Its derivative model, FLANG-BERT, outperforms FinBert on these datasets due to domain-specific enhancements.</p><p>• BloombergGPT <ref type="bibr" coords="3,214.72,535.39,16.69,8.64" target="#b30">[33]</ref> is a closed-source model based on BLOOM, trained extensively on diverse financial datasets, thereby encapsulating a broad spectrum of the financial domain.</p><p>• FinGPT <ref type="bibr" coords="3,180.19,565.70,15.65,8.64" target="#b34">[37,</ref><ref type="bibr" coords="3,197.99,565.70,12.40,8.64" target="#b36">39,</ref><ref type="bibr" coords="3,212.54,565.70,13.21,8.64" target="#b33">36]</ref> is an open-source LLM, fine-tuned from a general LLM using low-rank adaptation methods <ref type="bibr" coords="3,224.11,576.61,10.58,8.64" target="#b8">[9]</ref>, fostering accessibility for the broader community.</p><p>• PIXIU <ref type="bibr" coords="3,174.61,596.01,16.60,8.64" target="#b31">[34]</ref> functions as an evaluation benchmark and an instructional dataset. Its focus is solely on the dataset benchmark, exclusively evaluating models derived from Llama without considering other open-source LLMs.</p><p>Current research mainly uses Llama models as the base model for financial task evaluations, limiting understanding as different open-source models may excel in various tasks. A broader, more inclusive evaluation encompassing various open-source models could yield insights into task-specific performances and may unveil models that are inherently better aligned with specific financial applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Paradigm</head><p>Initially, we conduct a continuous evaluation of financial tasks while constructing instructions pertinent to each task, followed by the selection and evaluation of a base model. The Instruction Tuning paradigm outlined in this study, depicted in Figure <ref type="figure" coords="4,310.66,120.54,3.72,8.64" target="#fig_0">1</ref>, is carefully designed into three interconnected phases, each playing a crucial role in facilitating the seamless integration and thorough analysis of various financial NLP datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task-Specific Instruction Tuning</head><p>In the initial phase of our paradigm, Task-Specific Instruction Tuning, we meticulously analyze the foundational competencies of LLMs for individual NLP tasks within the finance sector. Each task is examined in isolation during this phase, allowing for a detailed evaluation of LLMs' inherent capabilities and performance. This focused approach generates in-depth insights into the strengths, efficacy, and areas needing improvement for each LLM regarding specific tasks and the ability to efficiently extract, process, and analyze information from various financial data sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Potential Challenges in Task-Specific Instruction Tuning</head><p>This dedicated approach, while robust, is not without challenges:</p><p>• Varying Task Complexity: Financial NLP tasks vary considerably in their level of complexity and specificity. As such, LLMs might exhibit proficiency in certain tasks while struggling with others that demand a deeper understanding of the financial domain or more advanced analytical skills.</p><p>• Quality of Financial Datasets: The quality and reliability of financial datasets used for taskspecific instruction tuning directly impact the effectiveness of the tuning process. Ensuring data accuracy, relevance, and completeness while avoiding biased or unrepresentative samples is crucial for the success of this phase.</p><p>• Performance Measurement: Establishing appropriate metrics and benchmarks to accurately measure and compare the performance of LLMs across various task-specific scenarios can be challenging given the unique characteristics of each task within the financial domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Addressing the Challenges in Task-Specific Instruction Tuning</head><p>Addressing the outlined challenges requires a multifaceted strategy combining data quality assurance, enhanced model training and testing procedures, and continuous performance monitoring.</p><p>1. Recognizing the varied complexity levels across different financial NLP tasks, we implement a dynamic Instruction Tuning approach. This approach is adaptive, changing the depth and breadth of tuning based on the complexity of the task at hand, thus ensuring optimal performance across tasks of varying difficulty and specificity.</p><p>2. Rigorous data validation and verification processes are instituted to ensure the quality and reliability of financial datasets utilized in the tuning process. These processes aim to verify data accuracy, completeness, and relevance, thus providing a solid foundation for effective task-specific Instruction Tuning.</p><p>3. We devise a set of comprehensive, task-appropriate performance metrics and benchmarks. Continuous refinement and validation of these metrics ensure they remain relevant and reflective of the unique characteristics and requirements of each task.</p><p>By addressing these challenges head-on, we ensure that the task-specific phase of our paradigm is both robust and reflective of the unique demands and challenges posed by the financial domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-Task Instruction Tuning</head><p>The Multi-Task Instruction Tuning phase evaluates the LLMs' versatility and adaptability across concurrent NLP tasks within finance. Here, various instructional tunings are integrated, enabling LLMs to perform multiple tasks simultaneously, offering insight into their multitasking capabilities.</p><p>This phase is designed to mirror the complex, multitasking environment that characterizes the financial sector, where the ability to concurrently process and analyze various forms of data is paramount. Therefore, it critically informs the practical utility and efficiency of deploying LLMs in real-world financial scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Potential Challenges in Multi-Task Instruction Tuning</head><p>While this phase is imperative, it introduces several challenges that must be navigatively addressed:</p><p>• Task Interference: One major challenge is task interference. When models are trained to perform multiple tasks concurrently, the learning for one task might interfere with the learning for another, affecting the overall performance adversely. • Computational Complexity: With the amalgamation of instructional tunings for various tasks, the computational complexity increases. Handling the elevated processing demands without compromising on efficiency and speed becomes challenging. • Optimal Task Weighting: Determining the appropriate balance or weighting among multiple tasks during training to ensure that no single task dominates the learning process is a non-trivial challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Addressing Challenges in Multi-Task Instruction Tuning</head><p>Addressing the inherent challenges in Multi-Task Instruction Tuning requires a streamlined approach combining optimized computation, efficient training protocols, and advanced evaluation techniques.</p><p>1. Advanced optimization techniques are employed to handle increased computational demands. Through efficient batching and parallel processing, computational loads are effectively distributed, ensuring fast and efficient training without sacrificing model quality. 2. Dynamic task weighting strategies are adopted to facilitate balanced learning across tasks.</p><p>These adaptive mechanisms adjust the weight assigned to each task's loss during training, promoting harmonious multi-task learning without dominance of any single task.</p><p>These strategic measures collectively address the challenges associated with Multi-Task Instruction Tuning, enabling the effective deployment of proficient LLMs in the financial domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Instruction Tuning for Zero-shot Ability</head><p>The final phase, "Instruction Tuning for Zero-shot Ability," enhances LLMs' zero-shot capabilities. In this crucial phase, LLMs face unprecedented scenarios and tasks, selected to assess their adaptability, learning agility, and response to novel challenges in the financial sector. The introduction of novel datasets and unseen tasks creates a rigorous testing environment for the models. This systematic approach allows for a detailed examination of the LLMs' robustness, flexibility, and problem-solving abilities, essential for operating in the rapidly changing financial landscape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Potential Challenges in Instruction Tuning for Zero-shot Ability</head><p>The complexity and novelty integrated into this phase inevitably introduce an array of challenges, each of which necessitates thoughtful consideration and strategic addressing:</p><p>• Hallucination: LLMs sometimes generate plausible but unfounded or hallucinated information in their responses, particularly when dealing with unfamiliar or unseen tasks. This phenomenon can lead to misinformation and misinterpretation of the data, which is especially perilous in the financial domain where precision is paramount. • Generalization vs. Specialization: Striking the optimal balance between generalization to new tasks and specialization in previously learned tasks is a perpetual challenge in zero-shot learning environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Addressing Challenges in Instruction Tuning for Zero-shot Ability</head><p>To effectively navigate through the challenges identified, strategic approaches have been employed:</p><p>1. To counteract hallucination issues, we implement a strategy of task reformulation. The models are trained with a more focused objective, making it easier for them to understand and categorize input data without generating extraneous information. This focused training approach narrows down the task gap between the newly reformulated tasks and the target task, thereby fostering a more controlled and accurate generation process.</p><p>2. An optimal balance between generalization to novel tasks and specialization in learned tasks is crucial. We use adaptive learning and fine-tuning techniques, dynamically adjusting the learning process based on the task at hand.</p><p>Through these carefully devised strategies, we mitigate identified challenges, promoting the effective development and tuning of LLMs for enhanced zero-shot capabilities in the financial domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation Detail</head><p>In this section, we expound upon our methodologies in Data Preparation, Instruction Construction, and Training. Comprehensive resources including datasets, codebases, and illustrative examples are accessible at <ref type="url" coords="6,154.20,269.13,350.84,8.30;6,108.00,280.04,81.09,8.30" target="https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark">https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/ FinGPT_Benchmark</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Preparation</head><p>In preparing the data, our approach aligns with the methodology utilized by BloombergGPT <ref type="bibr" coords="6,469.50,327.31,19.41,8.64" target="#b30">[33]</ref>, in which a selection of financial datasets from the FLUE benchmark <ref type="bibr" coords="6,366.98,338.22,18.73,8.64" target="#b21">[23]</ref> is adopted for various tasks.</p><p>Selection of Datasets: For the Sentiment Analysis (SA) task, we leverage datasets FPB <ref type="bibr" coords="6,466.51,354.61,19.89,8.64" target="#b15">[17]</ref> and FiQA-SA <ref type="bibr" coords="6,141.26,365.52,19.01,8.64" target="#b14">[16]</ref>, while for the Headline Classification (HC) task, the Headline dataset <ref type="bibr" coords="6,437.35,365.52,15.88,8.64" target="#b23">[25]</ref> is employed. Furthermore, the NER dataset <ref type="bibr" coords="6,225.84,376.43,15.85,8.64" target="#b19">[21]</ref> is utilized for Named Entity Recognition (NER) tasks. To enhance diversity within the data, particularly for the sentiment analysis task, additional datasets, TFNS <ref type="bibr" coords="6,483.48,387.34,20.52,8.64" target="#b13">[15]</ref> and NWGI <ref type="bibr" coords="6,146.57,398.25,20.86,8.64" target="#b33">[36]</ref>, were incorporated into the mix. This step was crucial to ensure that the models developed had exposure to a wide variety of data, promoting robustness and versatility in their application.</p><p>Financial Relation Extraction: Additionally, our implementation ventured into the domain of financial Relation Extraction (RE). For this endeavor, we engaged with the FinRED dataset <ref type="bibr" coords="6,485.46,447.36,15.83,8.64" target="#b22">[24]</ref>, providing a basis for the extraction and understanding of financial relations within the textual data.</p><p>Rationale Behind Dataset Choices: Datasets were carefully selected to cover a wide range of financial NLP tasks, with each contributing uniquely to the model's understanding and performance on specific tasks. Care was taken to ensure that the datasets were complementary, and their integration would facilitate a comprehensive and nuanced understanding of the model's capabilities and areas that required further refinement and tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Instruction Construction</head><p>Constructing precise instructions is pivotal for both task-specific and multi-task Instruction Tuning, with each task being guided by a unique instruction prompt.</p><p>Template Structure: The instruction template is structured as follows:</p><formula xml:id="formula_0" coords="6,108.00,609.27,221.25,9.03">Instruction: [prompt] Input: [input] Answer: [output]</formula><p>This template provides a standardized format, facilitating consistency across different tasks and experimental setups.</p><p>Instruction Formulation for Specific Tasks:</p><p>• Sentiment Analysis (SA) Task: Instructions for the SA task are directly adopted from FinGPT <ref type="bibr" coords="6,178.47,685.65,15.27,8.64" target="#b36">[39]</ref>, leveraging their previously established efficacy.</p><p>• Headline Classification (HC) Task: For the HC task, we have chosen to use Bloomberg's <ref type="bibr" coords="6,143.87,713.51,16.60,8.64" target="#b30">[33]</ref> set of instructions, taking advantage of their industry-aligned approach. • Named Entity Recognition (NER) and Relation Extraction (RE) Tasks: In the cases of NER and RE, instructions were meticulously crafted in-house to address the specific nuances and requirements of these tasks.</p><p>Multi-Task and Zero-Shot Experiment Adjustments: To facilitate multi-task and zero-shot experiments, modifications were made to the NER and RE tasks, reformatting them into classification tasks-dubbed NER(CLS) and RE(CLS). This alignment with SA and HC tasks not only enriched our set of tasks but also aimed to enhance the generalization capabilities of the LLMs.</p><p>Zero-Shot Experiment Instructions: An [Options] section is added to each instruction for standardization in zero-shot experiments, streamlining instructions and limiting unexpected answers.</p><p>ChatGPT was used to create ten unique instructions per task, with option order randomized in the training set for diversity. The updated zero-shot experiment template is provided below:</p><formula xml:id="formula_1" coords="7,108.00,443.22,299.34,9.03">Instruction: [prompt] Options: [options] Input: [input] Answer: [output]</formula><p>Concrete examples illustrating the constructed instructions are depicted in Figure <ref type="figure" coords="7,430.03,460.00,3.69,8.64" target="#fig_0">1</ref>, providing visual insights into the practical application of the instruction set within the experimental framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Detail</head><p>In our research, six open-source LLMs-Llama2-7B <ref type="bibr" coords="7,313.53,517.72,21.16,8.64" target="#b16">[18]</ref>, Falcon-7B[28], BLOOM-7.1B <ref type="bibr" coords="7,459.02,517.72,15.72,8.64" target="#b3">[4]</ref>, MPT-7B <ref type="bibr" coords="7,116.65,528.63,17.79,8.64" target="#b17">[19]</ref>, ChatGLM2-6B[11], and Qwen-7B <ref type="bibr" coords="7,280.41,528.63,15.82,8.64" target="#b5">[6]</ref>-are selected as the subjects for the application of our Instruction Tuning paradigm. Each of these models is of a comparable size and is used in their base form, without the inclusion of any instruction-tuned variants or chat versions, with the singular exception of ChatGLM2 (the base model of which has not been released).</p><p>Utilizing LoRA. Given the substantial computational resources necessitated by the fine-tuning process of these LLMs, our approach incorporates the use of LoRA <ref type="bibr" coords="7,371.87,588.65,14.67,8.64" target="#b8">[9]</ref>, maintained with a rank of 8 and a scaling factor (alpha) of 32, targeting the projection layers within attention modules.</p><p>In the three phases of Instruction Tuning:</p><p>• Task-specific job: epochs are set to 8 for SA, HC, and RE tasks due to their ample sample sizes. The NER task, possessing a limited sample size, warrants the setting of epochs to 50.</p><p>• Multi-task job: the models are exposed to a combined dataset of SA, HC, NER, RE, NER(CLS), and RE(CLS) for a total of 4 epochs. Tasks characterized by smaller sample sizes are oversampled to maintain balance.</p><p>• Zero-shot job: the models undergo fine-tuning on a consolidated dataset comprised of NER(CLS), RE(CLS), and HC for a single epoch, subsequently undergoing evaluation on the SA task. Checkpoints are systematically saved every 100 steps and are selected based on their evaluation loss pertaining to the SA task.</p><p>Model Parameters: Experiments used four RTX 3090 GPUs, with max token length of 512 and perdevice batch size of four, plus eight gradient accumulation steps. We employed AdamW optimizer <ref type="bibr" coords="8,485.13,117.17,16.09,8.64" target="#b12">[14]</ref>, with an initial learning rate of 1 × 10 -4 , linearly decaying to zero following a 3% warm-up in steps, utilizing FP16 precision for cost-effectiveness.</p><p>Training Cost Analysis: With GPU hourly rate at $3.36, task-specific jobs for six base models across four tasks took 30 hours. Multi-task and zero-shot jobs required about 60 hours due to increased instructions per base model, totaling 90 hours. Thus, the entire training cost was $302.4. Table <ref type="table" coords="8,131.82,290.91,3.83,8.64">2</ref>: Task-Specific Instruction Tuning Results Summary: Each row presents the F1-score of base models tuned on the specified task, along with their rankings in the bracket. The best model in each task is highlighted in bold. The average of rankings is computed to assess overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>5 Experiment Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Task-Specific Instruction Tuning</head><p>Result Overview. Table <ref type="table" coords="8,206.73,391.05,4.93,8.64">2</ref> summarizes the results of task-specific Instruction Tuning. For Sentiment Analysis (SA), we document the average performance of models across all sub-datasets, represented through the mean F1-score, with detailed performance metrics for each SA dataset available in Table <ref type="table" coords="8,108.00,423.78,3.81,8.64" target="#tab_2">3</ref>. The entity-level F1-score is reported for Named Entity Recognition (NER), whereas for Health Classification (HC) and Relation Extraction (RE), the F1-scores are reported respectively. For RE, we solely consider the F1-score for identified relations, excluding the (relation, subject, object) tuples.</p><p>Performance Insights. The experimental findings yield interesting insights. Notably, Llama2 delivers superior overall performance, as evidenced by its average ranking of second place across all tasks. Both Falcon and Qwen demonstrate versatility, yielding balanced performances across all tasks under consideration. In contrast, while BLOOM excels significantly at Information Extraction (IE) tasks such as NER and RE, it falls short in classification tasks like SA and HC, where it records the lowest performance. Although MPT secures the highest score in SA, it underperforms in NER and RE tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multi-Task Instruction Tuning</head><p>Performance Evaluation Setup. This subsection presents the performance evaluation of various LLMs following multi-task Instruction Tuning, and it provides a comparative analysis between models that underwent multi-task and task-specific tuning. Each model was trained on an aggregated dataset encompassing SA, HC, NER, RE, NER(CLS), and RE(CLS). Table <ref type="table" coords="8,408.64,604.37,4.96,8.64" target="#tab_2">3</ref> displays the results on the SA task and its sub-datasets, while Table <ref type="table" coords="8,287.89,615.28,4.98,8.64" target="#tab_3">4</ref> shows the results for NER, HC, and RE tasks.</p><p>Performance in Classification Tasks. In classification tasks, such as SA and HC, most models displayed a minor decline in performance when concurrently trained with unrelated tasks. An exception to this trend, Qwen consistently enhanced its performance across all SA sub-datasets. Additionally, Falcon also showed improvement in specific areas. Conversely, BLOOM, which already had limited success during the task-specific tuning phase, suffered the most substantial performance degradation in classification tasks after multi-task tuning. incorporation of RE(CLS) and additional financial NLP tasks, suggesting potential under-fitting during the task-specific tuning phase. While Llama2 and MPT exhibited progress in NER, not all models mirrored this improvement. Notably, these two models also displayed the most substantial enhancements in RE. BLOOM, in particular, made significant strides, outperforming Falcon and reaffirming its dominance in information extraction tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance in</head><p>Model Improvement Analysis. Despite its unsatisfying performance in the task-specific phase, MPT registered the most significant improvement in both NER and RE tasks, while Falcon and Chat-GLM2 experienced moderate gains in both tasks, further underlining the interconnected performance dynamics in similar tasks.</p><p>Summary of Findings. Llama2 and MPT not only displayed versatility by excelling in various tasks but also benefited from the multi-task learning environment. While models like Falcon, ChatGLM2, and Qwen maintained their baseline performances, BLOOM managed to enhance its strengths minimally. However, its weaknesses became more pronounced in a multi-task setting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Instruction Tuning for Zero-shot Ability</head><p>Training Setup and Modification. This subsection delineates the results of our examination on the zero-shot abilities of LLMs post-Instruction Tuning. For this evaluation, the LLMs were trained on three distinct classification tasks: HC, NER(CLS), and RE(CLS). Initially, we endeavored to employ the original NER and RE tasks for training purposes. However, these did not sufficiently activate the models' zero-shot abilities due to insufficient instruction diversity. This limitation led to issues such as model hallucination and inconsistency in response to the provided options.</p><p>Task Reformulation to Mitigate Hallucination. To mitigate this, we reformulated NER and RE tasks into classification tasks, thereby narrowing the task gap with the target SA task. Furthermore, considering the challenge in distinguishing between neutral sentiments and positive/negative ones in a zero-shot setting, all samples labeled "neutral" were excluded from the study.</p><p>Comparative Performance Insights. Table <ref type="table" coords="10,284.93,304.76,4.91,8.64" target="#tab_4">5</ref> presents the mean F1-score results for FiQA and FPB. ChatGLM2 stood out in zero-shot tasks, likely due to its chat-centric tuning. Falcon followed closely in overall performance. Llama2 and MPT, while lagging behind ChatGLM2 and Falcon, showed promise in classifying a subset of the samples. However, both BLOOM and Qwen struggled, often misclassifying responses as "positive". BLOOM's results were expected given its past struggles with classification, but Qwen's suboptimal performance was surprising.</p><p>Generalization Capability Insights. These findings are particularly illuminating as neither Chat-GLM2 nor Falcon excelled in the task-specific and multi-task Instruction Tuning phases but demonstrated significant generalization capabilities, understanding unseen instructions, and making accurate classifications during the zero-shot tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In conclusion, this paper presented an Instruction Tuning paradigm that includes task-specific, multitask, and zero-shot instruction tuning of LLMs within the financial sector. Our work articulated and showcased the diverse capabilities and potential limitations of different LLMs when subjected to various NLP tasks integral to finance. Through rigorous experimentation and analysis, the paper unveiled distinct performance patterns and offered valuable insights into how these models can be efficiently and effectively employed for specific financial applications.</p><p>Future work will focus on integrating additional open-source base models, investigating larger models with parameter sizes between 13 and 100 billion, and deepening efforts to enhance the robustness and generalization capabilities of Large Language Models (LLMs). We'll also develop strategies to reduce task interference and hallucination <ref type="bibr" coords="10,290.72,562.42,15.41,8.64" target="#b9">[10]</ref>, ensuring accurate and reliable model responses across diverse tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,176.35,305.46,259.30,8.64;3,167.38,78.35,151.62,199.22"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the proposed Instruction Tuning paradigm</figDesc><graphic coords="3,167.38,78.35,151.62,199.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,107.69,75.84,397.96,200.37"><head>Table 1 :</head><label>1</label><figDesc>Overview of tasks and datasets: The trailing (CLS) means the task can be formatted into a unified classification task. Number of samples are counted before augmented by hand-craft/gptgenerated prompts. Headline contains 11412 sample and 9 question for each sample. For each entity in NER, we ask models to classify its entity-type forming NER(CLS). For each relation in RE, we ask models to classify its relation-type forming RE(CLS).</figDesc><table coords="7,177.68,75.84,254.15,138.66"><row><cell>Task</cell><cell>Dataset</cell><cell>Total Samples</cell></row><row><cell></cell><cell>FPB</cell><cell>3634</cell></row><row><cell>Sentiment Analysis (CLS)</cell><cell>FiQA-SA TFNS</cell><cell>938 9543</cell></row><row><cell></cell><cell>NWGI</cell><cell>16184</cell></row><row><cell>Named Entity Recognition</cell><cell>NER</cell><cell>609</cell></row><row><cell>Headline Classification (CLS)</cell><cell>Headline</cell><cell>11412 × 9</cell></row><row><cell>Relation Extraction</cell><cell>FinRED</cell><cell>6768</cell></row><row><cell>Named Entity Recognition (CLS)</cell><cell>NER</cell><cell>1003</cell></row><row><cell>Relation Extraction (CLS)</cell><cell>FinRED</cell><cell>9657</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,108.00,702.22,396.00,19.94"><head>Table 3 :</head><label>3</label><figDesc>Information Extraction Tasks. The scenario differs for information extraction tasks like NER and RE. For RE, all models exhibited significant improvement, likely due to the Sentiment Analysis Instruction Tuning Results: The table reports detailed F1-scores for base models tuned during task-specific and multi-task phases on each sentiment analysis dataset. Arrows (↑↓) denote the influence of multi-task settings on Instruction Tuning results, with performance gains calculated between phases based on average F1 scores across all datasets.</figDesc><table coords="9,114.38,75.84,384.25,395.45"><row><cell>Phase</cell><cell></cell><cell cols="3">Dataset Llama2 Falcon</cell><cell>MPT</cell><cell cols="3">BLOOM ChatGLM2 Qwen</cell></row><row><cell></cell><cell></cell><cell>FPB</cell><cell>0.863</cell><cell>0.846</cell><cell>0.872</cell><cell>0.810</cell><cell>0.850</cell><cell>0.854</cell></row><row><cell></cell><cell></cell><cell>FiQA</cell><cell>0.871</cell><cell>0.840</cell><cell>0.863</cell><cell>0.771</cell><cell>0.864</cell><cell>0.867</cell></row><row><cell cols="2">Task-Specific</cell><cell>TFNS</cell><cell>0.896</cell><cell>0.893</cell><cell>0.907</cell><cell>0.840</cell><cell>0.859</cell><cell>0.883</cell></row><row><cell></cell><cell></cell><cell>NWGI</cell><cell>0.649</cell><cell>0.636</cell><cell>0.640</cell><cell>0.573</cell><cell>0.619</cell><cell>0.638</cell></row><row><cell></cell><cell></cell><cell>Avg</cell><cell>0.820</cell><cell>0.804</cell><cell>0.821</cell><cell>0.748</cell><cell>0.798</cell><cell>0.811</cell></row><row><cell></cell><cell></cell><cell>FPB</cell><cell cols="3">0.861↓ 0.845↓ 0.870↓</cell><cell>0.766↓</cell><cell>0.836↓</cell><cell>0.873↑</cell></row><row><cell></cell><cell></cell><cell>FiQA</cell><cell cols="3">0.825↓ 0.881↑ 0.863-</cell><cell>0.737↓</cell><cell>0.822↓</cell><cell>0.870↑</cell></row><row><cell cols="2">Multi-Task</cell><cell>TFNS</cell><cell cols="3">0.890↓ 0.880↓ 0.892↓</cell><cell>0.789↓</cell><cell>0.858↓</cell><cell>0.890↑</cell></row><row><cell></cell><cell></cell><cell>NWGI</cell><cell cols="3">0.652↑ 0.647↑ 0.651↑</cell><cell>0.530↓</cell><cell>0.618↓</cell><cell>0.653↑</cell></row><row><cell></cell><cell></cell><cell>Avg</cell><cell>0.807</cell><cell>0.813</cell><cell>0.819</cell><cell>0.701</cell><cell>0.784</cell><cell>0.822</cell></row><row><cell cols="3">Performance Gain</cell><cell>-1.3%</cell><cell cols="2">+0.7% -0.2%</cell><cell>-4.7%</cell><cell>-1.4%</cell><cell>+1.1%</cell></row><row><cell>Task</cell><cell cols="2">Phase</cell><cell>Llama2</cell><cell>Falcon</cell><cell>MPT</cell><cell cols="3">BLOOM ChatGLM2 Qwen</cell></row><row><cell cols="3">Task-Specific</cell><cell>0.637</cell><cell>0.619</cell><cell>0.615</cell><cell>0.729</cell><cell>0.645</cell><cell>0.679</cell></row><row><cell>NER</cell><cell cols="2">Multi-Task</cell><cell>0.678↑</cell><cell>0.600↓</cell><cell>0.682↑</cell><cell>0.709↓</cell><cell>0.629↓</cell><cell>0.666↓</cell></row><row><cell cols="4">Performance Gain +4.1%</cell><cell>-1.9%</cell><cell>+6.7%</cell><cell>-2.0%</cell><cell>-1.6%</cell><cell>-1.3%</cell></row><row><cell cols="3">Task-Specific</cell><cell>0.942</cell><cell>0.940</cell><cell>0.938</cell><cell>0.930</cell><cell>0.942</cell><cell>0.936</cell></row><row><cell>HC</cell><cell cols="2">Multi-Task</cell><cell>0.938↓</cell><cell>0.932↓</cell><cell>0.928↓</cell><cell>0.898↓</cell><cell>0.932↓</cell><cell>0.922↓</cell></row><row><cell cols="3">Performance Gain</cell><cell>-0.4%</cell><cell>-0.8%</cell><cell>-1.0%</cell><cell>-3.2%</cell><cell>-1.0%</cell><cell>-1.4%</cell></row><row><cell cols="3">Task-Specific</cell><cell>0.395</cell><cell>0.428</cell><cell>0.309</cell><cell>0.425</cell><cell>0.340</cell><cell>0.371</cell></row><row><cell>RE</cell><cell cols="2">Multi-Task</cell><cell>0.674↑</cell><cell>0.576↑</cell><cell>0.667↑</cell><cell>0.697↑</cell><cell>0.557↑</cell><cell>0.640↑</cell></row><row><cell cols="7">Performance Gain +27.2% +14.8% +35.8% +27.2%</cell><cell>+21.7%</cell><cell>26.9%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,107.69,484.88,397.56,41.36"><head>Table 4 :</head><label>4</label><figDesc>Multi-Task Instruction Tuning Summary: The table reports entity-level F1 scores for NER, relation-only F1 for RE, and standard classification F1 for HC. It includes both task-specific and multi-task models for comparison. Arrows (↑↓) signify performance gains from multi-task settings, calculated in each task's last row.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,107.69,75.84,396.31,66.78"><head>Table 5 :</head><label>5</label><figDesc>Zero-shot Sentiment Analysis Results: The zero-shot F1-scores on the Sentiment Analysis test datasets are reported for all base models. The two best models are highlighted in bold.</figDesc><table coords="10,159.99,75.84,289.52,37.80"><row><cell cols="6">Dataset Llama2 Falcon MPT BLOOM ChatGLM2 Qwen</cell></row><row><cell>FPB</cell><cell>0.621</cell><cell>0.791 0.599</cell><cell>0.576</cell><cell>0.803</cell><cell>0.576</cell></row><row><cell>FiQA</cell><cell>0.565</cell><cell>0.625 0.591</cell><cell>0.517</cell><cell>0.631</cell><cell>0.517</cell></row></table></figure>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledging these gaps, our work endeavors to present a more sophisticated and integrated paradigm, aiming to seamlessly intertwine open-source LLMs with intricate financial data, thereby proposing a robust solution for domain-specific applications.</p></div>
			</div>


			<div type="funding">
<div><p>. Supported in part by <rs type="funder">National Natural Science Foundation of China (NNSFC)</rs> grant <rs type="programName">12271363 Workshop on Instruction Tuning and Instruction Following at NeurIPS 2023</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Rb3U6em">
					<orgName type="program" subtype="full">12271363 Workshop on Instruction Tuning and Instruction Following at NeurIPS 2023</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,127.92,621.12,377.21,7.77;10,127.92,631.08,377.20,7.77;10,127.92,641.04,376.08,7.77;10,127.92,651.01,70.95,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coords="10,277.56,641.04,226.44,7.77;10,127.92,651.01,43.59,7.77">Falcon-40B: an open large language model with state-of-the-art performance</title>
		<author>
			<persName coords=""><forename type="first">Ebtesam</forename><surname>Almazrouei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hamza</forename><surname>Alobeidli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Abdulaziz</forename><surname>Alshamsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alessandro</forename><surname>Cappelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruxandra</forename><surname>Cojocaru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Merouane</forename><surname>Debbah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Etienne</forename><surname>Goffinet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Heslow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Launay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quentin</forename><surname>Malartic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Badreddine</forename><surname>Noune</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Baptiste</forename><surname>Pannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guilherme</forename><surname>Penedo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,127.92,667.49,376.08,7.93;10,127.92,677.45,90.16,7.93" xml:id="b1">
	<monogr>
		<title level="m" type="main" coords="10,178.84,667.64,263.09,7.77">Finbert: Financial sentiment analysis with pre-trained language models</title>
		<author>
			<persName coords=""><forename type="first">Dogu</forename><surname>Araci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10063</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,127.92,694.24,376.08,7.77;10,127.75,704.05,376.25,7.93;10,127.92,714.01,90.16,7.93" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jinze</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuai</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shusheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shijie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sinan</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.12966</idno>
		<title level="m" coords="10,182.22,704.20,262.73,7.77">Qwen-vl: A frontier large vision-language model with versatile abilities</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,127.92,75.97,284.56,7.93" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Bigscience</surname></persName>
		</author>
		<ptr target="https://huggingface.co/bigscience/bloomz-7b1" />
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,93.58,376.08,7.77;11,127.92,103.54,377.65,7.77;11,127.37,113.35,268.94,7.93" xml:id="b4">
	<analytic>
		<title level="a" type="main" coords="11,363.74,103.54,138.45,7.77">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,127.37,113.35,186.40,7.72">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,130.81,261.14,7.93" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Alibaba</forename><surname>Cloud</surname></persName>
		</author>
		<ptr target="https://huggingface.co/Qwen/Qwen-7B" />
		<title level="m" coords="11,185.94,130.96,30.84,7.77">Qwen-7b</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,148.42,376.08,7.77;11,127.92,158.23,376.08,7.93;11,127.92,168.19,350.17,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coords="11,454.83,148.42,49.17,7.77;11,127.92,158.38,218.15,7.77">Glm: General language model pretraining with autoregressive blank infilling</title>
		<author>
			<persName coords=""><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,361.88,158.23,142.12,7.72;11,127.92,168.19,174.62,7.72">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="320" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,185.80,376.08,7.77;11,127.92,195.76,307.31,7.77" xml:id="b7">
	<monogr>
		<title level="m" type="main" coords="11,453.59,185.80,50.41,7.77;11,127.92,195.76,222.32,7.77">GLM: general language model pretraining with autoregressive blank infilling</title>
		<author>
			<persName coords=""><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="320" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,213.22,376.08,7.77;11,127.50,223.03,376.50,7.93;11,127.67,232.99,117.23,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coords="11,186.24,223.18,201.81,7.77">LoRA: Low-rank adaptation of large language models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yelong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Phillip</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zeyuan</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuanzhi</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shean</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weizhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,398.39,223.03,105.61,7.72;11,127.67,232.99,91.08,7.72">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,250.60,376.08,7.77;11,127.92,260.41,376.08,7.93;11,127.70,270.37,101.09,7.93" xml:id="b9">
	<analytic>
		<title level="a" type="main" coords="11,234.76,260.56,199.05,7.77">Survey of hallucination in natural language generation</title>
		<author>
			<persName coords=""><forename type="first">Ziwei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rita</forename><surname>Frieske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Etsuko</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ye</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jin</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,441.76,260.41,62.25,7.72;11,127.70,270.37,26.13,7.72">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,315.40,377.65,7.77;11,127.92,325.21,377.50,7.93" xml:id="b10">
	<analytic>
		<title level="a" type="main" coords="11,242.76,315.40,258.87,7.77">Design guidelines for prompt engineering text-to-image generative models</title>
		<author>
			<persName coords=""><forename type="first">Vivian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lydia</forename><forename type="middle">B</forename><surname>Chilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,137.61,325.21,296.69,7.72">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2022 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,342.82,377.21,7.77;11,127.92,352.78,376.08,7.77;11,127.92,362.59,356.32,7.93" xml:id="b11">
	<analytic>
		<title level="a" type="main" coords="11,234.73,352.78,269.27,7.77;11,127.92,362.74,80.64,7.77">FinRL-Meta: Market environments and benchmarks for data-driven financial reinforcement learning</title>
		<author>
			<persName coords=""><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ziyi</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingyang</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiechao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongyang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christina</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhaoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,215.31,362.59,186.40,7.72">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1835" to="1849" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,380.20,290.07,7.77" xml:id="b12">
	<monogr>
		<title level="m" type="main" coords="11,252.79,380.20,139.33,7.77">Decoupled weight decay regularization</title>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,397.50,377.57,7.93;11,127.92,407.47,79.81,7.93" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Neural</forename><surname>Magic</surname></persName>
		</author>
		<ptr target="https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment" />
		<title level="m" coords="11,182.04,397.66,112.84,7.77">Twitter financial news sentiment</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,425.07,376.08,7.77;11,127.60,435.04,376.40,7.77;11,127.62,444.85,276.86,7.93" xml:id="b14">
	<analytic>
		<title level="a" type="main" coords="11,204.34,435.04,282.88,7.77">WWW&apos;18 open challenge: financial opinion mining and question answering</title>
		<author>
			<persName coords=""><forename type="first">Macedo</forename><surname>Maia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Siegfried</forename><surname>Handschuh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">André</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ross</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manel</forename><surname>Zarrouk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,127.62,444.85,183.02,7.72">Companion Proceedings of the the Web Conference</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1941" to="1942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,462.46,377.32,7.77;11,127.92,472.27,376.08,7.93;11,127.42,482.23,123.22,7.93" xml:id="b15">
	<analytic>
		<title level="a" type="main" coords="11,420.58,462.46,84.66,7.77;11,127.92,472.42,175.33,7.77">Good debt or bad debt: Detecting semantic orientations in economic texts</title>
		<author>
			<persName coords=""><forename type="first">Pekka</forename><surname>Malo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ankur</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pekka</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jyrki</forename><surname>Wallenius</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pyry</forename><surname>Takala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,309.61,472.27,194.39,7.72;11,127.42,482.23,39.12,7.72">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="782" to="796" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,499.69,264.38,7.93" xml:id="b16">
	<analytic>
		<title/>
		<ptr target="https://huggingface.co/meta-llama/Llama-2-7b" />
	</analytic>
	<monogr>
		<title level="j" coords="11,127.92,499.84,43.99,7.77">Meta. Llama</title>
		<imprint>
			<biblScope unit="page" from="2" to="7" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,517.14,242.97,7.93" xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Mosaicml</surname></persName>
		</author>
		<ptr target="https://huggingface.co/mosaicml/mpt-7b" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,534.75,377.20,7.77;11,127.92,544.71,376.08,7.77;11,127.92,554.52,342.38,7.93" xml:id="b18">
	<analytic>
		<title level="a" type="main" coords="11,314.82,544.71,189.19,7.77;11,127.92,554.67,57.40,7.77">Training language models to follow instructions with human feedback</title>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,192.40,554.52,186.40,7.72">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,572.13,376.40,7.77;11,127.92,581.94,376.08,7.93;11,127.37,591.90,293.64,7.93" xml:id="b19">
	<analytic>
		<title level="a" type="main" coords="11,382.22,572.13,122.10,7.77;11,127.92,582.09,160.49,7.77">Domain adaption of named entity recognition to support credit risk assessment</title>
		<author>
			<persName coords=""><forename type="first">Julio</forename><surname>Cesar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Salinas</forename><surname>Alvarado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,305.33,581.94,198.66,7.72;11,127.37,591.90,98.00,7.72">Proceedings of the Australasian Language Technology Association Workshop 2015</title>
		<meeting>the Australasian Language Technology Association Workshop 2015<address><addrLine>Parramatta, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12">December 2015</date>
			<biblScope unit="page" from="84" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,127.92,609.51,376.08,7.77;11,127.92,619.47,376.24,7.77;11,127.92,629.29,297.76,7.93" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gallé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m" coords="11,437.26,619.47,66.90,7.77;11,127.92,629.44,146.80,7.77">A 176b-parameter open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,127.92,646.89,377.20,7.77;11,127.92,656.86,376.08,7.77;11,127.92,666.67,281.08,7.93" xml:id="b21">
	<monogr>
		<title level="m" type="main" coords="11,292.75,656.86,211.25,7.77;11,127.92,666.82,130.06,7.77">When flue meets flang: Benchmarks and large pre-trained language model for financial domain</title>
		<author>
			<persName coords=""><forename type="first">Raj Sanjay</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kunal</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dheeraj</forename><surname>Eidnani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Agam</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wendi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sudheer</forename><surname>Chava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Natraj</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charese</forename><surname>Smiley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiaao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.00083</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,127.92,684.27,377.21,7.77;11,127.92,694.09,376.08,7.93;11,127.92,704.05,376.23,7.93;11,127.92,714.16,83.10,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coords="11,194.21,694.24,206.91,7.77">Finred: A dataset for relation extraction in financial domain</title>
		<author>
			<persName coords=""><forename type="first">Soumya</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tapas</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arusarka</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ajay</forename><surname>Kumar Meena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Koustuv</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niloy</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,417.41,694.09,86.59,7.72;11,127.92,704.05,149.48,7.93">Companion Proceedings of the Web Conference 2022, WWW &apos;22</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="595" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.92,76.13,377.65,7.77" xml:id="b23">
	<monogr>
		<title level="m" type="main" coords="12,259.51,76.13,220.56,7.77">Impact of news on the commodity market: Dataset and results</title>
		<author>
			<persName coords=""><forename type="first">Ankur</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tanmay</forename><surname>Khandait</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.92,94.06,376.08,7.77;12,127.92,103.87,376.08,7.93;12,127.37,113.83,160.88,7.93" xml:id="b24">
	<analytic>
		<title level="a" type="main" coords="12,252.58,94.06,251.43,7.77;12,127.92,104.02,42.10,7.77">Automatic domain-specific sentiment lexicon generation with label propagation</title>
		<author>
			<persName coords=""><forename type="first">Yen-Jen</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hung-Yu</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="12,190.23,103.87,313.77,7.72;12,127.37,113.83,85.34,7.72">Proceedings of International Conference on Information Integration and Web-based Applications &amp; Services</title>
		<meeting>International Conference on Information Integration and Web-based Applications &amp; Services</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="53" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.92,131.92,377.20,7.77;12,127.92,141.88,106.61,7.77" xml:id="b25">
	<monogr>
		<title level="m" type="main" coords="12,214.84,131.92,286.72,7.77">Introducing mpt-7b: A new standard for open-source, commercially usable llms</title>
		<author>
			<persName coords=""><forename type="first">Nlp</forename><surname>Mosaicml</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2023" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.92,177.74,377.20,7.77;12,127.92,187.71,376.08,7.77;12,127.92,197.52,209.61,7.93" xml:id="b26">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<title level="m" coords="12,396.58,187.71,107.42,7.77;12,127.92,197.67,58.73,7.77">Open and efficient foundation language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,215.60,376.39,7.77;12,127.92,225.56,376.08,7.77;12,127.92,235.38,230.77,7.93" xml:id="b27">
	<monogr>
		<title level="m" type="main" coords="12,387.62,225.56,116.38,7.77;12,127.92,235.53,79.90,7.77">Llama 2: Open foundation and fine-tuned chat models</title>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,253.46,376.08,7.77;12,127.92,263.27,377.20,7.93;12,127.92,273.39,20.17,7.77" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kelvin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nan</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc V</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01652</idno>
		<title level="m" coords="12,204.80,263.42,174.34,7.77">Finetuned language models are zero-shot learners</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,291.32,376.08,7.77;12,127.92,301.28,376.08,7.77;12,127.92,311.09,175.49,7.93" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jules</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quchen</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Sandborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Olea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henry</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashraf</forename><surname>Elnashar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jesse</forename><surname>Spencer-Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">C</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.11382</idno>
		<title level="m" coords="12,278.80,301.28,225.20,7.77;12,127.92,311.24,25.06,7.77">A prompt pattern catalog to enhance prompt engineering with chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,329.18,376.08,7.77;12,127.92,339.14,377.65,7.77;12,127.92,348.95,143.62,7.93" xml:id="b30">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Shijie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vadim</forename><surname>Dabravolski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prabhanjan</forename><surname>Kambadur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gideon</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bloomberggpt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17564</idno>
		<title level="m" coords="12,373.96,339.14,128.03,7.77">A large language model for finance</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,367.03,376.08,7.77;12,127.92,376.84,376.08,7.93;12,127.92,386.81,121.46,7.93" xml:id="b31">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Qianqian</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weiguang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yanzhao</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alejandro</forename><surname>Lopez-Lira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Pixiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05443</idno>
		<title level="m" coords="12,184.54,377.00,291.04,7.77">A large language model, instruction data and evaluation benchmark for finance</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,404.89,377.65,7.77;12,127.37,414.70,177.70,7.93" xml:id="b32">
	<analytic>
		<title level="a" type="main" coords="12,307.56,404.89,194.36,7.77">Natural language based financial forecasting: a survey</title>
		<author>
			<persName coords=""><forename type="first">Erik</forename><surname>Frank Z Xing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roy</forename><forename type="middle">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="12,127.37,414.70,102.49,7.72">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="73" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.92,432.79,377.03,7.83;12,127.68,442.75,156.93,7.83" xml:id="b33">
	<monogr>
		<title level="m" type="main" coords="12,205.47,432.79,193.50,7.77">Data-centric fingpt. open-source for open finance</title>
		<author>
			<persName coords=""><forename type="first">Hongyang</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://github.com/AI4Finance-Foundation/FinGPT" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.92,460.68,376.08,7.77;12,127.92,470.49,175.00,7.93" xml:id="b34">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Hongyang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christina</forename><forename type="middle">Dan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06031</idno>
		<title level="m" coords="12,342.02,460.68,161.98,7.77;12,127.92,470.65,24.12,7.77">Fingpt: Open-source financial large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,488.58,376.08,7.77;12,127.92,498.39,377.20,7.93;12,127.92,508.50,20.17,7.77" xml:id="b35">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanyu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhuoyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wendi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02414</idno>
		<title level="m" coords="12,211.34,498.54,167.85,7.77">Glm-130b: An open bilingual pre-trained model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,526.44,376.39,7.77;12,127.92,536.25,365.08,7.93" xml:id="b36">
	<monogr>
		<title level="m" type="main" coords="12,326.78,526.44,177.53,7.77;12,127.92,536.40,214.21,7.77">Instruct-fingpt: Financial sentiment analysis by instruction tuning of general-purpose large language models</title>
		<author>
			<persName coords=""><forename type="first">Boyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongyang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.12659</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,127.92,554.33,376.40,7.77;12,127.92,564.14,372.67,7.93" xml:id="b37">
	<monogr>
		<title level="m" type="main" coords="12,143.35,564.29,206.73,7.77">Large language models are human-level prompt engineers</title>
		<author>
			<persName coords=""><forename type="first">Yongchao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrei</forename><forename type="middle">Ioan</forename><surname>Muresanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ziwen</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keiran</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Silviu</forename><surname>Pitis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harris</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.01910</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
